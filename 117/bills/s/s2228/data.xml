<bill session="117" type="s" number="2228" updated="2022-12-31T05:26:16Z">
  <state datetime="2021-06-24">REFERRED</state>
  <status>
    <introduced datetime="2021-06-24"/>
  </status>
  <introduced datetime="2021-06-24"/>
  <titles>
    <title type="official" as="introduced">A bill to amend section 230 of the Communications Act of 1934 to correct shortcomings in how that section addresses content moderation, content creation and development, and content distribution.</title>
    <title type="display">DISCOURSE Act</title>
    <title type="short" as="introduced">DISCOURSE Act</title>
    <title type="short" as="introduced">Disincentivizing Internet Service Censorship of Online Users and Restrictions on Speech and Expression Act</title>
  </titles>
  <sponsor bioguide_id="R000595"/>
  <cosponsors>
    <cosponsor bioguide_id="B001310" joined="2021-06-24"/>
  </cosponsors>
  <actions>
    <action datetime="2021-06-24">
      <text>Introduced in Senate</text>
    </action>
    <action datetime="2021-06-24" state="REFERRED">
      <text>Read twice and referred to the Committee on Commerce, Science, and Transportation.</text>
    </action>
  </actions>
  <committees>
    <committee code="SSCM" name="Senate Commerce, Science, and Transportation" subcommittee="" activity="Referral"/>
  </committees>
  <relatedbills/>
  <subjects>
    <term name="Science, technology, communications"/>
  </subjects>
  <amendments/>
  <summary date="2022-07-14T11:43:37Z" status="Introduced in Senate">Disincentivizing Internet Service Censorship of Online Users and Restrictions on Speech and Expression Act or the DISCOURSE Act

This bill limits federal liability protections for a user or provider of an interactive computer service (e.g., a social media company) related to content provided by third parties. It also requires a provider that offers its service through a mass-market offering to the public to disclose information about its content moderation activities.

The bill removes liability protections (sometimes referred to as section 230 protection) for a provider with a dominant market share if the provider

 promotes or suppresses a viewpoint through its content moderation, including by affecting a content creator's revenue; uses automated processes (e.g., algorithms) to target and amplify content provided to a user who has not requested or searched for the content; or solicits, funds, modifies, or otherwise contributes to content. Currently, a provider retains liability protections even when it restricts access to materials that it considers objectionable. Under this bill, a provider retains protections if restricted materials fall, based on an objectively reasonable belief, into a prescribed list of harmful or unlawful categories.

Additionally, the liability protections shall not apply to providers that (1) restrict access to content in a manner that burdens the exercise of religion, or (2) fail to comply with an existing requirement to notify customers of options for limiting a minor's access to harmful online content (e.g., parental controls).

The bill also changes legal procedures related to the liability protections, including by specifying that the protection serves as an affirmative defense.</summary>
</bill>
